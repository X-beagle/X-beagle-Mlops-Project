{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1fddb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Specify your AWS Region\n",
    "aws_region='ap-northeast-2'\n",
    "\n",
    "# Create a low-level SageMaker service client.\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "# Role to give SageMaker permission to access AWS services.\n",
    "sagemaker_role= \"arn:aws:sts::907729080149:assumed-role/SagemakerFullAccess/SageMaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa7034f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a variable w/ the model S3 URI\n",
    "s3_bucket = 'x-beagle' # Provide the name of your S3 bucket\n",
    "bucket_prefix='asyncronize'\n",
    "model_s3_key = f\"{bucket_prefix}/model.tar.gz\"\n",
    "\n",
    "#Specify S3 bucket w/ model\n",
    "model_url = f\"s3://{s3_bucket}/{model_s3_key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32e20e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch 1.12 버전을 사용(기본에 없음...)\n",
    "container = '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/pytorch-inference:1.12.0-gpu-py38'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62c9fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "model_name = 'x-beagle-asyncronize'\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = sagemaker_role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': model_url,\n",
    "        'Environment': {\n",
    "            'TS_MAX_REQUEST_SIZE': '100000000',\n",
    "            'TS_MAX_RESPONSE_SIZE': '100000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        },\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31f9deb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EndpointConfig: arn:aws:sagemaker:ap-northeast-2:907729080149:endpoint-config/x-beagleEndpointConfig-2024-05-24-18-29-46\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = f\"x-beagleEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "\n",
    "# The name of the model that you want to host. This is the name that you specified when creating the model.\n",
    "model_name='x-beagle-asyncronize'\n",
    "\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name, # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"x-beagle\", # The name of the production variant.\n",
    "            \"ModelName\": model_name, \n",
    "            \"InstanceType\": \"ml.g4dn.4xlarge\", # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": f\"s3://{s3_bucket}/{bucket_prefix}/output\"\n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            # (Optional) Specify the max number of inflight invocations per instance\n",
    "            # If no value is provided, Amazon SageMaker will choose an optimal value for you\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 4\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c81b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the endpoint.The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = 'x-beagle-asyncronize-endpoint' \n",
    "\n",
    "# The name of the endpoint configuration associated with this endpoint.\n",
    "endpoint_config_name='x-beagleEndpointConfig-2024-05-24-18-29-46'\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beffb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-level client representing Amazon SageMaker Runtime\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name='ap-northeast-2')\n",
    "\n",
    "# Specify the location of the input. Here, a single SVM sample\n",
    "input_location = \"s3://x-beagle/additional_data\"\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account. \n",
    "endpoint_name='x-beagle-asyncronize-endpoint'\n",
    "\n",
    "# After you deploy a model into production using SageMaker hosting \n",
    "# services, your client applications use this API to get inferences \n",
    "# from the model hosted at the specified endpoint.\n",
    "response = sagemaker_runtime.invoke_endpoint_async(\n",
    "                            EndpointName=endpoint_name, \n",
    "                            InputLocation=input_location,\n",
    "                            InvocationTimeoutSeconds=3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71b02835",
   "metadata": {},
   "outputs": [
    {
     "ename": "WaiterError",
     "evalue": "Waiter ObjectExists failed: Max attempts exceeded. Previously accepted state: Matched expected HTTP status code: 404",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWaiterError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Wait until the result file exists\u001b[39;00m\n\u001b[1;32m     50\u001b[0m waiter \u001b[38;5;241m=\u001b[39m s3_client\u001b[38;5;241m.\u001b[39mget_waiter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_exists\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m response \u001b[38;5;241m=\u001b[39m s3_client\u001b[38;5;241m.\u001b[39mget_object(Bucket\u001b[38;5;241m=\u001b[39mbucket_name, Key\u001b[38;5;241m=\u001b[39mobject_key)\n\u001b[1;32m     54\u001b[0m result \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/waiter.py:55\u001b[0m, in \u001b[0;36mcreate_waiter_with_client.<locals>.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mWaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/waiter.py:388\u001b[0m, in \u001b[0;36mWaiter.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m         reason \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax attempts exceeded. Previously accepted state: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    386\u001b[0m             \u001b[38;5;241m%\u001b[39m (acceptor\u001b[38;5;241m.\u001b[39mexplanation)\n\u001b[1;32m    387\u001b[0m         )\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaiterError(\n\u001b[1;32m    389\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    390\u001b[0m         reason\u001b[38;5;241m=\u001b[39mreason,\n\u001b[1;32m    391\u001b[0m         last_response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(sleep_amount)\n",
      "\u001b[0;31mWaiterError\u001b[0m: Waiter ObjectExists failed: Max attempts exceeded. Previously accepted state: Matched expected HTTP status code: 404"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Create a low-level client representing Amazon SageMaker Runtime\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name='ap-northeast-2')\n",
    "\n",
    "# Create a low-level client representing Amazon SageMaker\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name='ap-northeast-2')\n",
    "\n",
    "# Specify the location of the input. Here, a single SVM sample\n",
    "input_location = \"s3://x-beagle/additional_data/test.jpg\"\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account. \n",
    "endpoint_name='x-beagle-asyncronize-endpoint'\n",
    "\n",
    "# After you deploy a model into production using SageMaker hosting \n",
    "# services, your client applications use this API to get inferences \n",
    "# from the model hosted at the specified endpoint.\n",
    "response = sagemaker_runtime.invoke_endpoint_async(\n",
    "                            EndpointName=endpoint_name, \n",
    "                            InputLocation=input_location,\n",
    "                            InvocationTimeoutSeconds=3600)\n",
    "\n",
    "# Wait for the async inference to complete\n",
    "output_location = None\n",
    "max_attempts = 10000  # Increase the maximum number of attempts\n",
    "attempt = 0\n",
    "\n",
    "while output_location is None and attempt < max_attempts:\n",
    "    endpoint_description = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    if 'OutputConfig' in endpoint_description['AsyncInferenceConfig']:\n",
    "        outputs = endpoint_description['AsyncInferenceConfig']['OutputConfig']['S3OutputPath']\n",
    "        output_location = f\"{outputs}/{response['InferenceId']}.out\"\n",
    "    time.sleep(20)  # Wait for 5 seconds before checking again\n",
    "    attempt += 1\n",
    "\n",
    "if output_location is None:\n",
    "    raise ValueError(\"Timed out waiting for inference result.\")\n",
    "\n",
    "# Download the inference result from S3\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = output_location.split('/')[2]\n",
    "object_key = '/'.join(output_location.split('/')[3:])\n",
    "\n",
    "# Wait until the result file exists\n",
    "waiter = s3_client.get_waiter('object_exists')\n",
    "waiter.wait(Bucket=bucket_name, Key=object_key)\n",
    "\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "result = response['Body'].read().decode('utf-8')\n",
    "\n",
    "# Process the inference result\n",
    "orig_image = cv2.imread('baggage.jpg')\n",
    "image_height, image_width, _ = orig_image.shape\n",
    "model_height, model_width = 300, 300\n",
    "x_ratio = image_width/model_width\n",
    "y_ratio = image_height/model_height\n",
    "\n",
    "if 'boxes' in result:\n",
    "    for idx,(x1,y1,x2,y2,conf,lbl) in enumerate(result['boxes']):\n",
    "        # Draw Bounding Boxes\n",
    "        x1, x2 = int(x_ratio*x1), int(x_ratio*x2)\n",
    "        y1, y2 = int(y_ratio*y1), int(y_ratio*y2)\n",
    "        color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "        cv2.rectangle(orig_image, (x1,y1), (x2,y2), color, 4)\n",
    "        cv2.putText(orig_image, f\"Class: {int(lbl)}\", (x1,y1-40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        cv2.putText(orig_image, f\"Conf: {int(conf*100)}\", (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        if 'masks' in result:\n",
    "            # Draw Masks\n",
    "            mask = cv2.resize(np.asarray(result['masks'][idx]), dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            for c in range(3):\n",
    "                orig_image[:,:,c] = np.where(mask>0.5, orig_image[:,:,c]*(0.5)+0.5*color[c], orig_image[:,:,c])\n",
    "\n",
    "if 'probs' in result:\n",
    "    # Find Class\n",
    "    lbl = result['probs'].index(max(result['probs']))\n",
    "    color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "    cv2.putText(orig_image, f\"Class: {int(lbl)}\", (20,20), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ab764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
