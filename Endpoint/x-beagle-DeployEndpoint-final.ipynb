{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2441fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sagemaker, subprocess, boto3\n",
    "from datetime import datetime\n",
    "from sagemaker import s3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5e91a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/requirements.txt\n",
    "nvgpu\n",
    "opencv-python\n",
    "torchvision\n",
    "seaborn\n",
    "ultralytics\n",
    "omegaconf==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "766d31c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/inference.py\n",
    "import numpy as np\n",
    "import torch, os, json, io, cv2, time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print(\"Executing model_fn from inference.py ...\")\n",
    "    env = os.environ\n",
    "    model = YOLO(os.path.join(model_dir, env['YOLOV8_MODEL']))\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print(\"Executing input_fn from inference.py ...\")\n",
    "    if request_content_type:\n",
    "        jpg_original = np.load(io.BytesIO(request_body), allow_pickle=True)\n",
    "        jpg_as_np = np.frombuffer(jpg_original, dtype=np.uint8)\n",
    "        img = cv2.imdecode(jpg_as_np, flags=-1)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported content type: \" + request_content_type)\n",
    "    return img\n",
    "    \n",
    "def predict_fn(input_data, model):\n",
    "    print(\"Executing predict_fn from inference.py ...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        result = model(input_data)\n",
    "    return result\n",
    "        \n",
    "def output_fn(prediction_output, content_type):\n",
    "    print(\"Executing output_fn from inference.py ...\")\n",
    "    infer = {}\n",
    "    for result in prediction_output:\n",
    "        if 'boxes' in result._keys and result.boxes is not None:\n",
    "            infer['boxes'] = result.boxes.numpy().data.tolist()\n",
    "        if 'masks' in result._keys and result.masks is not None:\n",
    "            infer['masks'] = result.masks.numpy().data.tolist()\n",
    "        if 'keypoints' in result._keys and result.keypoints is not None:\n",
    "            infer['keypoints'] = result.keypoints.numpy().data.tolist()\n",
    "        if 'probs' in result._keys and result.probs is not None:\n",
    "            infer['probs'] = result.probs.numpy().data.tolist()\n",
    "    return json.dumps(infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f07e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# YOLO 모델 파일 경로\n",
    "model_path = '/home/ec2-user/SageMaker/runs/detect/train/weights/best.pt'\n",
    "\n",
    "# 모델 파일을 'code' 디렉토리로 복사\n",
    "os.system(f'cp {model_path} code/model.pt')\n",
    "\n",
    "# 'code' 디렉토리를 tar.gz 아카이브 파일로 압축\n",
    "bashCommand = \"tar -cpzf model.tar.gz code/\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6691f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import s3\n",
    "\n",
    "bucket = \"s3://x-beagle\"\n",
    "model_data = s3.S3Uploader.upload(\"model.tar.gz\", bucket + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e2ab5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model_name = 'model.pt'\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "model = PyTorchModel(entry_point='inference.py',\n",
    "                     model_data=model_data,\n",
    "                     framework_version='1.12',\n",
    "                     py_version='py38',\n",
    "                     role=role,\n",
    "                     env={'TS_MAX_RESPONSE_SIZE':'20000000', 'YOLOV8_MODEL': model_name},\n",
    "                     sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56b530d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "INSTANCE_TYPE = 'ml.m5.4xlarge'\n",
    "ENDPOINT_NAME = 'x-beagle-yolov8-' + str(datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S-%f'))\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1,\n",
    "                         instance_type=INSTANCE_TYPE,\n",
    "                         deserializer=JSONDeserializer(),\n",
    "                         endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dcb6b38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://ap-northeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/x-beagle-yolov8-2024-05-24-16-31-26-467501 in account 907729080149 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m resized_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(orig_image, (model_height, model_width))\n\u001b[1;32m     13\u001b[0m payload \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, resized_image)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx,(x1,y1,x2,y2,conf,lbl) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Draw Bounding Boxes\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_predictor.py:212\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://ap-northeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/x-beagle-yolov8-2024-05-24-16-31-26-467501 in account 907729080149 for more information."
     ]
    }
   ],
   "source": [
    "import cv2, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "orig_image = cv2.imread('baggage.jpg')\n",
    "\n",
    "image_height, image_width, _ = orig_image.shape\n",
    "model_height, model_width = 300, 300\n",
    "x_ratio = image_width/model_width\n",
    "y_ratio = image_height/model_height\n",
    "\n",
    "resized_image = cv2.resize(orig_image, (model_height, model_width))\n",
    "payload = cv2.imencode('.jpg', resized_image)[1].tobytes()\n",
    "result = predictor.predict(payload)\n",
    "\n",
    "if 'boxes' in result:\n",
    "    for idx,(x1,y1,x2,y2,conf,lbl) in enumerate(result['boxes']):\n",
    "        # Draw Bounding Boxes\n",
    "        x1, x2 = int(x_ratio*x1), int(x_ratio*x2)\n",
    "        y1, y2 = int(y_ratio*y1), int(y_ratio*y2)\n",
    "        color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "        cv2.rectangle(orig_image, (x1,y1), (x2,y2), color, 4)\n",
    "        cv2.putText(orig_image, f\"Class: {int(lbl)}\", (x1,y1-40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        cv2.putText(orig_image, f\"Conf: {int(conf*100)}\", (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        if 'masks' in result:\n",
    "            # Draw Masks\n",
    "            mask = cv2.resize(np.asarray(result['masks'][idx]), dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            for c in range(3):\n",
    "                orig_image[:,:,c] = np.where(mask>0.5, orig_image[:,:,c]*(0.5)+0.5*color[c], orig_image[:,:,c])\n",
    "\n",
    "if 'probs' in result:\n",
    "    # Find Class\n",
    "    lbl = result['probs'].index(max(result['probs']))\n",
    "    color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "    cv2.putText(orig_image, f\"Class: {int(lbl)}\", (20,20), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd9e3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
